<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Configuration on Rui&#39;s Home Page</title>
    <link>http://xmruibi.github.io/tags/configuration/</link>
    <description>Recent content in Configuration on Rui&#39;s Home Page</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <managingEditor>xmruibi@gmail.com (Rui Bi)</managingEditor>
    <webMaster>xmruibi@gmail.com (Rui Bi)</webMaster>
    <copyright>(c) 2015 Rui Bi.</copyright>
    <lastBuildDate>Sat, 10 Oct 2015 23:56:15 -0700</lastBuildDate>
    <atom:link href="http://xmruibi.github.io/tags/configuration/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>How to do the insite search in Hugo?</title>
      <link>http://xmruibi.github.io/code/BleveSearch/</link>
      <pubDate>Sat, 10 Oct 2015 23:56:15 -0700</pubDate>
      <author>xmruibi@gmail.com (Rui Bi)</author>
      <guid>http://xmruibi.github.io/code/BleveSearch/</guid>
      <description>

&lt;p&gt;Since I tried to avoid using the Google tool, searching insite content in static site like Hugo seems a tough thing for me.  However, I just found &lt;a href=&#34;https://github.com/blevesearch/hugoidx&#34;&gt;Bleeve Search&lt;/a&gt;, which is a great tool to assist the insite search.&lt;/p&gt;

&lt;p&gt;There are three steps to adding search to your site. First, you must build the index. Second, you must host the index. Third, you add a search page to your site.&lt;/p&gt;

&lt;h3 id=&#34;building-the-index&#34;&gt;Building the Index&lt;/h3&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Preparation: Check you have installed Go. Two ways to install Go, see the instruction in &lt;a href=&#34;https://golang.org/dl/&#34;&gt; Download GO&lt;/a&gt;. Also, be awared to the GOPATH&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;export %GOPATH = &amp;quot;.../...&amp;quot;
source etc/profile
echo $GOPATH
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Be sured you&amp;rsquo;ve also installed Mercurial. Check it by command &lt;code&gt;hg&lt;/code&gt;. You can use &lt;code&gt;brew&lt;/code&gt; to install it.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;brew install hg
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Install &lt;strong&gt;hugoidx&lt;/strong&gt; - this is the command we will use build the search index.  Anytime you update your content and regenerate your site using the &lt;code&gt;hugo&lt;/code&gt; command, you&amp;rsquo;ll also want to rebuild your search index.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go get github.com/blevesearch/hugoidx
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;cd &amp;lt;your hugo site&amp;gt;&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;hugoidx&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;You should now have a file named &lt;code&gt;search.bleve&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;hosting-the-index&#34;&gt;Hosting the Index&lt;/h3&gt;

&lt;p&gt;In order to host the index we need to run a small Go program that is available on the internet.  To simplify this process, we have built a reusable application called &lt;code&gt;bleve-hosted&lt;/code&gt;.  You can use this application safely answer queries to the index (read-only operations).&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;p&gt;Install &lt;code&gt;bleve-hosted&lt;/code&gt;&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;go get github.com/blevesearch/bleve-hosted
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;cd $GOPATH/src/github.com/blevesearch/bleve-hosted&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;&lt;code&gt;bleve-hosted&lt;/code&gt;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Test that its working:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;curl http://localhost:8080/api/test.bleve/_search -d &#39;{&amp;quot;query&amp;quot;:{&amp;quot;query&amp;quot;:&amp;quot;bleve&amp;quot;}}&#39;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;The resulting JSON should include &amp;laquo;total_hits&amp;raquo;: 1&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Copy the &lt;code&gt;search.bleve&lt;/code&gt; index you generated earlier into your &lt;code&gt;indexes/&lt;/code&gt; folder.  (This can really be anywhere, it will always look for an &lt;code&gt;indexes/&lt;/code&gt; folder relative to the current working directly when you launch &lt;code&gt;bleve-hosted&lt;/code&gt;.)&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Restart &lt;code&gt;bleve-hosted&lt;/code&gt; and optionally configure your server to keep this process running long term (init-scripts, etc)&lt;/p&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;add-search-to-your-site&#34;&gt;Add Search to your Site&lt;/h3&gt;

&lt;p&gt;Finally, we&amp;rsquo;re ready to add a search page to our site.  Several files were downloaded as a part of the &lt;code&gt;hugoidx&lt;/code&gt; package to help you get started.  Feel free to customize these files to best adapt them to your site.&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;&lt;code&gt;cd &amp;lt;your hugo site&amp;gt;&lt;/code&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Copy the main search page:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;cp $GOPATH/src/github.com/blevesearch/hugoidx/search.md content/
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Check and copy two Javascript files in my Github:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;https://github.com/xmruibi/xmruibi.github.io/blob/master/js/handlebars.js
https://github.com/xmruibi/xmruibi.github.io/blob/master/js/search.js
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Copy these two files into your &lt;code&gt;static/&lt;/code&gt; folder. Also, make sure you&amp;rsquo;ve &lt;code&gt;jquery.min.js&lt;/code&gt; in this folder.&lt;/p&gt;

&lt;p&gt;handlebars.js is used to render search results using a simple template syntax.&lt;br /&gt;
search.js is our custom code to bind everything together.&lt;/p&gt;

&lt;p&gt;jQuery is used to make AJAX requests from the browser to &lt;code&gt;bleve-hosted&lt;/code&gt;.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Update your layout to include these javascript files.  For many sites this will be in a file like &lt;code&gt;layouts/partial/footer.html&lt;/code&gt; or &lt;code&gt;themes/&amp;lt;your theme&amp;gt;/layouts/partials/footer.html&lt;/code&gt;.  In the section where javascript files are being included you&amp;rsquo;ll want to add:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;&amp;lt;script src=&amp;quot;/js/jquery.min.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script src=&amp;quot;/js/handlebars.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&amp;lt;script src=&amp;quot;/js/search.js&amp;quot;&amp;gt;&amp;lt;/script&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Finally, we need to update search.js to point to the correct URL for &lt;code&gt;bleve-hosted&lt;/code&gt;.  On line 2 of &lt;code&gt;static/js/search.js&lt;/code&gt; modify the value:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;var searchURL = &#39;http://&amp;lt;your server&amp;gt;:8080/api/search.bleve/_search&#39;
&lt;/code&gt;&lt;/pre&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;h3 id=&#34;touch-the-search-function&#34;&gt;Touch the Search function&lt;/h3&gt;

&lt;p&gt;You need to setup file &lt;code&gt;search.html&lt;/code&gt; in &lt;code&gt;layout/partials/modules/site/link&lt;/code&gt;, which is for the search bar in navgation sidebar. And also a &lt;code&gt;search.md&lt;/code&gt; file in your content folder.&lt;/p&gt;

&lt;p&gt;Here provided a great CSS to generate the beautiful search bar. Please check &lt;a href =&#34;https://github.com/xmruibi/xmruibi.github.io/blob/master/css/search.css&#34;&gt; Code &lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Make you search form includes both components:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;    &amp;lt;input id=&amp;quot;page&amp;quot; name=&amp;quot;p&amp;quot; value=&amp;quot;1&amp;quot; type=&amp;quot;hidden&amp;quot;/&amp;gt;
    &amp;lt;input id=&amp;quot;query&amp;quot; name=&amp;quot;q&amp;quot; type=&amp;quot;search&amp;quot; placeholder=&amp;quot;Search&amp;quot; /&amp;gt;
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Spring Boot App with Elastic Search Indexing Service</title>
      <link>http://xmruibi.github.io/code/ElasticSearch/</link>
      <pubDate>Mon, 10 Aug 2015 23:56:15 -0700</pubDate>
      <author>xmruibi@gmail.com (Rui Bi)</author>
      <guid>http://xmruibi.github.io/code/ElasticSearch/</guid>
      <description>

&lt;p&gt;This article shows an example to build a bridge between Spring-Boot App and Elastic Search Indexing Service.&lt;/p&gt;

&lt;h2 id=&#34;1-elastic-search-install&#34;&gt;1. Elastic Search Install&lt;/h2&gt;

&lt;p&gt;Install elastic search is very easy&lt;/p&gt;

&lt;h3 id=&#34;install-elastic-search&#34;&gt;Install Elastic Search&lt;/h3&gt;

&lt;h4 id=&#34;start-elastic-search&#34;&gt;Start Elastic Search&lt;/h4&gt;

&lt;pre&gt;&lt;code&gt;    # windows: cd yourPath: service install
                            service start
                            service stop
    # Mac: cd $ELASTIC_HOME: elasticsearch
&lt;/code&gt;&lt;/pre&gt;

&lt;h4 id=&#34;check-your-service-by-input-the-url-localhost-9200-in-your-browser&#34;&gt;Check your service by input the url &lt;code&gt;localhost:9200&lt;/code&gt; in your browser.&lt;/h4&gt;

&lt;h4 id=&#34;cluster-name&#34;&gt;Cluster Name&lt;/h4&gt;

&lt;p&gt;If cluster name is not &amp;laquo;elasticsearch&amp;raquo;, it may cause the run failed when your Java code trying to build elastic search instance. There should be an exception( NoNodeClientException: None of node configed) when your indexing the data.&lt;/p&gt;

&lt;p&gt;Please change your cluster name into &amp;laquo;elasticsearch&amp;raquo; in your elasticsearch install path.
 $ELASTIC_HOME/config/elasticsearch.yml : clustername = elasticsearch&lt;/p&gt;

&lt;h2 id=&#34;2-creat-index-by-spring-data-elasticsearch-api&#34;&gt;2. Creat Index by Spring-data-elasticsearch API&lt;/h2&gt;

&lt;p&gt;Here is a example from my project. It shows how I creat an index for music by Bulk method, which is provided by Elastic Java API.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;@Service
public class MusicIndexingService {

	private final static Logger logger = Logger
			.getLogger(MusicIndexingService.class);

	@Autowired	
	private Client client ;
	
	private ObjectMapper mapper = new ObjectMapper();

	/**
	 * The bulk index method
	 * @param musicCollection for index
	 */
	public void bulkIndex(List&amp;lt;IndexedMusic&amp;gt; musicCollection) {
		client.delete(new DeleteRequest(&amp;quot;musics&amp;quot;));
		logger.info(&amp;quot;Indexing bulk request of &amp;quot; + musicCollection.size()
				+ &amp;quot; documents&amp;quot;);
		BulkRequestBuilder bulkRequest = client.prepareBulk();
		for (IndexedMusic music : musicCollection) {
			String json = null;
			try {
				json = mapper.writeValueAsString(music);
			} catch (JsonProcessingException e) {
				throw new RuntimeException(e);
			}
			bulkRequest.add(client.prepareIndex(&amp;quot;musics&amp;quot;, &amp;quot;music&amp;quot;,
					UUID.randomUUID().toString()).setSource(json));
		}
		BulkResponse response = bulkRequest.execute().actionGet();
		if (response.hasFailures()) {
			throw new RuntimeException(
					&amp;quot;there was an error indexing the bulk request of &amp;quot;
							+ musicCollection.size() + &amp;quot; documents: &amp;quot; +response.buildFailureMessage());
		}
	}
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;## 3. Search the index:
 Search a music by name.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;/**
	 * This is keyword search method in comment contents field in music object
	 * @param keyword
	 * @return
	 */
	public List&amp;lt;Music&amp;gt; findMusic(String keyword) {
		QueryBuilder matchquery = QueryBuilders.fuzzyLikeThisFieldQuery(
				&amp;quot;commentContents&amp;quot;).likeText(keyword);
		SearchRequestBuilder requestBuilder = client.prepareSearch(&amp;quot;musics&amp;quot;)
				.setQuery(matchquery);
		SearchResponse response = requestBuilder.execute().actionGet();
		SearchHits hits = response.getHits();
		List&amp;lt;String&amp;gt; musicIdsList = new ArrayList&amp;lt;String&amp;gt;();
		Iterator&amp;lt;SearchHit&amp;gt; iterator = hits.iterator();
		while (iterator.hasNext()) {
			musicIdsList.add(iterator.next().getSource().get(&amp;quot;id&amp;quot;).toString());
		}
		return (List&amp;lt;Music&amp;gt;) musicRepository.findAll(musicIdsList);
	}

&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
    <item>
      <title>Architecture Design on Social Music Search project</title>
      <link>http://xmruibi.github.io/code/SpringBoot/</link>
      <pubDate>Sun, 09 Aug 2015 10:56:15 -0700</pubDate>
      <author>xmruibi@gmail.com (Rui Bi)</author>
      <guid>http://xmruibi.github.io/code/SpringBoot/</guid>
      <description>

&lt;h2 id=&#34;framework-why-spring-boot&#34;&gt;Framework: Why Spring Boot?&lt;/h2&gt;

&lt;p&gt;Spring framework goes every where in current enterprise application. However, most of people are familiar with Spring MVC. Here I just want to introduce a new Spring Boot project. Hear what its official document said:
&amp;gt; Spring Boot makes it easy to create stand-alone, production-grade Spring based Applications that you can &amp;laquo;just run&amp;raquo;.&lt;/p&gt;

&lt;p&gt;Yes, unlike Spring MVC, the Spring Boot require less configuration and easier to deploy on remote virtual machine or cloud computing platform. Spring Boot has following features:&lt;/p&gt;

&lt;h4 id=&#34;features&#34;&gt;Features&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Create stand-alone Spring applications&lt;/li&gt;
&lt;li&gt;Embed Tomcat, Jetty or Undertow directly (no need to deploy WAR files)&lt;/li&gt;
&lt;li&gt;Provide opinionated &amp;lsquo;starter&amp;rsquo; POMs to simplify your Maven configuration&lt;/li&gt;
&lt;li&gt;Automatically configure Spring whenever possible&lt;/li&gt;
&lt;li&gt;Provide production-ready features such as metrics, health checks and externalized configuration&lt;/li&gt;
&lt;li&gt;Absolutely no code generation and no requirement for XML configuration&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;spring-boot-app-configuration&#34;&gt;Spring Boot App Configuration&lt;/h2&gt;

&lt;p&gt;The Spring Boot requires some basic configuration and set up the bootstrap entrance:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;It doesn&amp;rsquo;t need &lt;code&gt;web.xml&lt;/code&gt; whic is common for Spring MVC;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Set up the bootstrap by Maven plugin.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Bootstrap Main function (Entrance of Spring Boot App): MusicSearchApplication;&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;Spring Configuration (config package)&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ApplicationConfig
```java
@Configuration
@PropertySource(&amp;laquo;classpath:application.properties&amp;raquo;) // point out the application.properties as configuration source
public class ApplicationConfig {
public @Bean LoggingEventListener mongoEventListener() {
    return new LoggingEventListener();
}&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;}
&lt;code&gt;
- WebMVCConfig
&lt;/code&gt;
@Configuration
@ComponentScan({&amp;laquo;com.musicSearch.core.controller&amp;raquo;,&amp;laquo;com.musicSearch.core.service&amp;raquo;,&amp;laquo;com.musicSearch.core.domain&amp;raquo;}) // here is important to do component scan
public class WebMVCConfig extends WebMvcConfigurerAdapter {
    @Override
    public void addViewControllers(ViewControllerRegistry registry) {
        registry.addViewController(&amp;laquo;/static&amp;raquo;)
                .setViewName(&amp;laquo;forward:/index.html&amp;raquo;);
        // point out the .css/.js or other static files target and default home page
    }
}
&lt;code&gt;
- ApplicationInitializer: Core entrance configuration
&lt;/code&gt;java
@Configuration
@EnableAutoConfiguration
@Import({ MongoDBConfig.class, ElasticSearchConfig.class,
        ApplicationConfig.class, WebMVCConfig.class,
        RepositoryRestMvcConfiguration.class })
public class MusicSearchApplication extends SpringBootServletInitializer {&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;public static void main(String[] args) {
    SpringApplication.run(MusicSearchApplication.class, args);
}


@Override
protected SpringApplicationBuilder configure(
        SpringApplicationBuilder application) {
    return application.sources(MusicSearchApplication.class);
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;}
```&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;design-detail&#34;&gt;Design Detail&lt;/h2&gt;

&lt;p&gt;Here is how I design my Social Music Search project with Spring Boot:&lt;/p&gt;

&lt;h3 id=&#34;restful-serivce-to-do-the-backend-and-frontend-communication&#34;&gt;RESTful Serivce to do the backend and frontend communication&lt;/h3&gt;

&lt;h4 id=&#34;spring-data-rest&#34;&gt;Spring-Data-REST&lt;/h4&gt;

&lt;p&gt;Based on Spring Boot as backend, I set up the RESTful interface by using Spring-Data-REST API:
- Config: ApplicationConfig;
- service;
- controller;&lt;/p&gt;

&lt;h3 id=&#34;non-sql-database-mongodb-to-be-the-database-solution&#34;&gt;Non-SQL database, MongoDB, to be the database solution&lt;/h3&gt;

&lt;p&gt;Spring-Data-MongoDB&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;config: MongoDBConfig;&lt;/li&gt;
&lt;li&gt;repository;&lt;/li&gt;
&lt;li&gt;domain: Music, BulletComment, User, Genre&amp;hellip;;&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;indexing-service&#34;&gt;Indexing Service&lt;/h3&gt;

&lt;p&gt;Spring-Data-ElasticSearch&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;config: ElasticSearchConfig; (port:9300)&lt;/li&gt;
&lt;li&gt;index.repository;&lt;/li&gt;
&lt;li&gt;index.domain: Indexed Music;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;reference&#34;&gt;Reference&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;http://projects.spring.io/spring-boot/&#34;&gt;Spring Official Site&lt;/a&gt;&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>How to Input and Output with Mongo DB Data on Hadoop Platform</title>
      <link>http://xmruibi.github.io/code/MongoDBwithHadoop/</link>
      <pubDate>Thu, 16 Apr 2015 12:56:15 -0700</pubDate>
      <author>xmruibi@gmail.com (Rui Bi)</author>
      <guid>http://xmruibi.github.io/code/MongoDBwithHadoop/</guid>
      <description>

&lt;p&gt;In the previous article, I&amp;rsquo;ve talked about how to distributed a Mongo DB database in multiple virtual machine. Here, I&amp;rsquo;d like to discuss how we can make data stream between Mongo DB and Hadoop. In fact, the format from MongoDB cannot directly used in Hadoop Map Reduce function. You have to use Mongo Hadoop API to assist you for finishing this difficult connection between MongoDB and Hadoop.&lt;/p&gt;

&lt;h2 id=&#34;introduction&#34;&gt;Introduction&lt;/h2&gt;

&lt;p&gt;The MongoDB Connector for Hadoop is a plugin for Hadoop that provides the ability to use MongoDB as an input source and/or an output destination. The major advantage is that once the connector is implemented, the analytic power of Hadoop can be utilized with the MongoDB storage architecture.
&amp;gt; “The Connector presents MongoDB as a Hadoop-compatible file system allowing a MapReduce job to read from MongoDB directly without first copying it to HDFS, thereby eliminating the need to move Terabytes of data across the network. MapReduce jobs can pass queries as filters, so avoiding the need to scan entire collections, and can also take advantage of MongoDB’s rich indexing capabilities including geospatial, text-search, array, compound and sparse indexes”&lt;/p&gt;

&lt;h2 id=&#34;procedure&#34;&gt;Procedure&lt;/h2&gt;

&lt;p&gt;Once we choose MongoDB as the I/O target, all of our I/O format needs to fit with MongoDB document format, thus we must use either JSON or BSON. So the entire procedure when Hadoop works with MongoDB is shown as follows:
- Create MongoDB URL builder with multiple Mongos (Routers) as Database entrances
- Set one MongoDB collection as input source with MongoDB URL builder
- Use Hadoop as Map-Reduce computing framework.
- Override Mapper class with BSON format as value in.
- Override Reduce class addressing the BSON data and output the data with MongodbUpdateWritable format
- Set another MongoDB collection as output destination  with MongoDB URL builder&lt;/p&gt;

&lt;h2 id=&#34;talk-is-cheap-show-me-the-code&#34;&gt;Talk is cheap, show me the code!&lt;/h2&gt;

&lt;h3 id=&#34;access-to-mongo-db&#34;&gt;Access to Mongo DB&lt;/h3&gt;

&lt;p&gt;By create MongoDB URL builder, the hadoop platform can detect the database position. However, we have multiple Mongo DB routers as Database entrances. So we just save our entry IP address as a list.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;private MongoClientURIBuilder ShardedDBURIBuilder() {
		// mainly host
		String mainHost = &amp;quot;44XX.XXX.XXX.X01&amp;quot;;

		// set up the option entrances when the main one shut down
		List&amp;lt;ServerAddress&amp;gt; serverSeeds;
		MongoClient mongoClient = null;
		serverSeeds = new ArrayList&amp;lt;ServerAddress&amp;gt;();
		try {
			serverSeeds.add(new ServerAddress(&amp;quot;4XX.XXX.XXX.X02&amp;quot;, 27017));
			serverSeeds.add(new ServerAddress(&amp;quot;4XX.XXX.XXX.X03&amp;quot;, 27017));
			mongoClient = new MongoClient(serverSeeds);
			mongoClient.getMongoClientOptions();
		} catch (UnknownHostException e) {
			log.error(e + &amp;quot;&amp;quot; + e.getCause());
		}

		MongoClientURIBuilder uriBuilder = new MongoClientURIBuilder();
		uriBuilder.addHost(mainHost, 27017);
		uriBuilder.options(mongoClient.getMongoClientOptions());
		return uriBuilder;
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Then we know where is the Mongo DB! But we still need to locate the collection in MongoDB and more detailed information. Here we go:&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;MongoClientURIBuilder uriBuilder = ShardedDBURIBuilder();
uriBuilder.collection(&amp;quot;stock&amp;quot;, &amp;quot;symbols&amp;quot;);
MongoClientURI inputURI = uriBuilder.build();
MongoConfigUtil.setInputURI(getConf(), inputURI);
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;build-our-own-mapper-and-reducer&#34;&gt;Build our own mapper and reducer!&lt;/h3&gt;

&lt;p&gt;Here I use my project about stock information crawler as an example. Mapper read the stock symbol data from the MongoDB. Then it get a list of symbol name in mapper. The mapper has separated that list and the reducer should read different part of list and search the stock information according to the partial symbol name list.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Override Mapper class with BSON format as value in.&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class SymbolsMapper extends Mapper&amp;lt;Object, BSONObject, Text, IntWritable&amp;gt;{
    @Override
    public void map(Object key, BSONObject val, final Context context) 
        throws IOException, InterruptedException {
    	System.out.println(val.get(&amp;quot;symbol&amp;quot;)+&amp;quot;  Mapper Getted!!&amp;quot;);
        context.write(new Text((val.get(&amp;quot;symbol&amp;quot;)).toString()), 
        		new IntWritable(1));
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;Override Reduce class addressing the BSON data and output the data with MongodbUpdateWritable format&lt;/li&gt;
&lt;/ul&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public class SymbolsReducer extends Reducer&amp;lt;Text, IntWritable, NullWritable, MongoUpdateWritable&amp;gt;{
	
    @Override
    public void reduce(final Text pKey, final Iterable&amp;lt;IntWritable&amp;gt; pValues,
                        final Context pContext )
            throws IOException, InterruptedException{
    	    
        StockCrawler stockCrawler = new StockCrawler();
        
        // get symbol from keyIn 
        Quote quote = stockCrawler.getHistQuotesBySymbol(pKey.toString());
        if(quote==null||quote.getSymbolName()==null||quote.getHistorical_quotes()==null)
        	return;
        // get Quote info, set new id
        BasicBSONObject query = new BasicBSONObject(&amp;quot;_id&amp;quot;, quote.getKey());
       
        // set symbol name and symbol quotes
        BasicBSONObject stockQuote = new BasicBSONObject();
        stockQuote.put(&amp;quot;symbol&amp;quot;, quote.getSymbolName());
        ArrayList&amp;lt;Object&amp;gt; historical_quotes =  quote.getHistorical_quotes();
        
        BasicBSONObject update = new BasicBSONObject(&amp;quot;$set&amp;quot;, stockQuote);
        update.append(&amp;quot;$pushAll&amp;quot;, new BasicBSONObject(&amp;quot;historical_quotes&amp;quot;, historical_quotes));
        
        pContext.write(null, new MongoUpdateWritable(query, update, true, false));
    }
}
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;output-back-to-mongo-db&#34;&gt;Output back to Mongo DB&lt;/h3&gt;

&lt;p&gt;The output procedure is very simliar with the input one. But just the difference on the target collection in Mongo DB.&lt;/p&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;MongoClientURI outputURI = uriBuilder.build();
MongoConfigUtil.setOutputURI(getConf(), outputURI);
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;the-overview-on-this-connector&#34;&gt;The overview on this connector:&lt;/h3&gt;

&lt;pre&gt;&lt;code class=&#34;language-java&#34;&gt;public MongoMapredStockCrawler() {
		setConf(new Configuration());

		if (MongoTool.isMapRedV1()) {
			MapredMongoConfigUtil.setInputFormat(getConf(),
					com.mongodb.hadoop.mapred.MongoInputFormat.class);
			MapredMongoConfigUtil.setOutputFormat(getConf(),
					com.mongodb.hadoop.mapred.MongoOutputFormat.class);
		} else {
			MongoConfigUtil.setInputFormat(getConf(), MongoInputFormat.class);
			MongoConfigUtil.setOutputFormat(getConf(), MongoOutputFormat.class);
		}

		MongoClientURIBuilder uriBuilder = ShardedDBURIBuilder();
		uriBuilder.collection(&amp;quot;stock&amp;quot;, &amp;quot;symbols&amp;quot;);
		MongoClientURI inputURI = uriBuilder.build();
		uriBuilder.collection(&amp;quot;stock&amp;quot;, &amp;quot;quotes&amp;quot;);
		MongoClientURI outputURI = uriBuilder.build();

		MongoConfigUtil.setInputURI(getConf(), inputURI);
		MongoConfigUtil.setOutputURI(getConf(), outputURI);

		MongoConfigUtil.setMapper(getConf(), SymbolsMapper.class);
		MongoConfigUtil.setReducer(getConf(), SymbolsReducer.class);

		MongoConfigUtil.setMapperOutputKey(getConf(), Text.class);
		MongoConfigUtil.setMapperOutputValue(getConf(), IntWritable.class);

		MongoConfigUtil.setOutputKey(getConf(), IntWritable.class);
		MongoConfigUtil.setOutputValue(getConf(), BSONWritable.class);
	}
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;conclusion&#34;&gt;Conclusion&lt;/h2&gt;

&lt;p&gt;This is very typical example when people need to read data from Mongo DB and process the data on Hadoop platform and then back the data to Mongo DB. Since there is very little instruction about this work, I just shared my idea on that.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Distributed MongoDB Configuration</title>
      <link>http://xmruibi.github.io/code/DistributedMongoDB/</link>
      <pubDate>Tue, 10 Mar 2015 22:56:15 -0700</pubDate>
      <author>xmruibi@gmail.com (Rui Bi)</author>
      <guid>http://xmruibi.github.io/code/DistributedMongoDB/</guid>
      <description>

&lt;p&gt;How to shard the distributed Mongo DB in remote VMs? Here is what I did during a project using Mongo DB as Database and using Hadoop as computing framework.&lt;/p&gt;

&lt;h2 id=&#34;sharded-mongodb-configuration&#34;&gt;Sharded MongoDB Configuration&lt;/h2&gt;

&lt;p&gt;The following graph is the architecture of how I set three VMs with different port to simulate the real sharding pattern(which need 15 machines actually)&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://xmruibi.github.io/media/Sharded%20MongoDB.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;

&lt;p&gt;The following procedure is how I configured MongoDB on remote three VMs.&lt;/p&gt;

&lt;h3 id=&#34;1-set-up-data-path-config-file-and-log-file-paths-in-each-node-with-mongos-config-shard1-shard2-shard3-directory-name&#34;&gt;1. Set up data path, config file and log file paths in each node with mongos 、config 、 shard1 、shard2、shard3 (directory name)&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;mkdir -p /data/mongos/log
sudo chmod -R 777 /data/mongos/log
mkdir -p /data/config/data
sudo chmod -R 777 /data/config/data
mkdir -p /data/config/log
sudo chmod -R 777 /data/config/log
mkdir -p /data/mongos/log
sudo chmod -R 777 /data/mongos/log
mkdir -p /data/shard1/data
sudo chmod -R 777 /data/shard1/data
mkdir -p /data/shard1/log
sudo chmod -R 777 /data/shard1/log
mkdir -p /data/shard2/data
sudo chmod -R 777 /data/shard2/data
mkdir -p /data/shard2/log
sudo chmod -R 777 /data/shard2/log
mkdir -p /data/shard3/data
sudo chmod -R 777 /data/shard3/data
mkdir -p /data/shard3/log
sudo chmod -R 777 /data/shard3/log
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;2-make-a-plan-of-port-number-and-modify-some-config-parameter-in-mongod-conf&#34;&gt;2. Make a plan of port number and modify some config parameter in mongod.conf&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;mongod --configsvr --dbpath /data/config/data --port 27019 --logpath /data/config/log/config.log --fork


mongos  --configdb 45.55.188.234:27019,45.55.186.238:27019,104.131.106.22:27019  --port 27017   --logpath  /data/mongos/log/mongos.log --fork

## or 
## These codes can migration configuration 

rsync -az /data/configdb mongo-config1.example.net:/data/configdb
rsync -az /data/configdb mongo-config2.example.net:/data/configdb

nano etc/mongod.conf

### This is important!!
set bing_ip = 0.0.0.0; for remote login
set default mongod: 27019 
## !Otherwise your mongos port(27017) will be blocked
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;3-config-sharding-setting-on-each-vm&#34;&gt;3. Config sharding setting on each VM&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;### set up shards ports and dbpath and log path
mongod --shardsvr --replSet shard1 --port 22001 --dbpath /data/shard1/data  --logpath /data/shard1/log/shard1.log --fork --journal  --oplogSize 10
mongod --shardsvr --replSet shard2 --port 22002 --dbpath /data/shard2/data  --logpath /data/shard2/log/shard2.log --fork --journal  --oplogSize 10
mongod --shardsvr --replSet shard3 --port 22003 --dbpath /data/shard3/data  --logpath /data/shard3/log/shard3.log --fork --journal  --oplogSize 10


# Shard_1 in Node(45.55.188.234)
mongo  127.0.0.1:22001
use admin
config = { _id:&amp;quot;shard1&amp;quot;, members:[
                     {_id:0,host:&amp;quot;45.55.188.234:22001&amp;quot;},
                     {_id:1,host:&amp;quot;45.55.186.238:22001&amp;quot;},
                {_id:2,host:&amp;quot;104.131.106.22:22001&amp;quot;,arbiterOnly:true}
                ]
         }
rs.initiate(config);

# Shard_2 in Node(45.55.186.238)
mongo  127.0.0.1:22002
use admin
config = { _id:&amp;quot;shard2&amp;quot;, members:[
                     {_id:0,host:&amp;quot;45.55.186.238:22002&amp;quot;},
                     {_id:1,host:&amp;quot;104.131.106.22:22002&amp;quot;},
                {_id:2,host:&amp;quot;45.55.188.234:22002&amp;quot;,arbiterOnly:true}
                ]
         }
rs.initiate(config);

# Shard_3 in Node(104.131.106.22)
mongo  127.0.0.1:22003
use admin
config = { _id:&amp;quot;shard3&amp;quot;, members:[
                     {_id:0,host:&amp;quot;104.131.106.22:22003&amp;quot;},
                     {_id:1,host:&amp;quot;45.55.188.234:22003&amp;quot;},
           {_id:2,host:&amp;quot;45.55.186.238:22003&amp;quot;,arbiterOnly:true}
                ]
         }
rs.initiate(config);
## if you need to reconfig, please use Cmd( rs.reconfig(your_para) )
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;4-add-shard-config-just-in-one-of-vms&#34;&gt;4. Add Shard Config just in one of VMs&lt;/h3&gt;

&lt;p&gt;It seems no master mode concept in MongoDB. So just choose one of it. Config Sharding info in mongos; I also made the sharding part on different machines (e.g. Primary Shard1 on Server One, Primary Shard2 on Server Two).&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;## no specific addr/port 
mongo
use admin

db.runCommand({addshard : &amp;quot;shard1/45.55.188.234:22001,45.55.186.238:22001,104.131.106.22:22001&amp;quot;});

db.runCommand({addshard: &amp;quot;shard2/45.55.186.238:22002,104.131.106.22:22002,45.55.188.234:22002&amp;quot;});

db.runCommand({addshard : &amp;quot;shard3/104.131.106.22:22003,45.55.188.234:22003,45.55.186.238:22003&amp;quot;});

## if you need to reset your previous setting
## 
db.runCommand( { removeShard: &amp;quot;shard1&amp;quot; } )

#Test:
db.runCommand( { enablesharding :&amp;quot;stock&amp;quot;});
db.runCommand( { shardcollection : &amp;quot;stock.quotes&amp;quot;,key : {&amp;quot;_id&amp;quot;: 1} })

for (var i = 1; i &amp;lt;= 100000; i++) db.table1.save({id:i,&amp;quot;test1&amp;quot;:&amp;quot;testval1&amp;quot;});


use admin
db.addUser(&#39;test&#39;,&#39;test&#39;)
db.auth(&#39;test&#39;,&#39;test&#39;)
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;5-some-commmands-for-check-database-status&#34;&gt;5. Some Commmands for check Database Status;&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;db.stats();

show databases

db.dropDatabase()

db.printShardingStatus()
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;6-misc&#34;&gt;6. Misc.&lt;/h3&gt;

&lt;pre&gt;&lt;code&gt;## Sometimes export jar failed
 zip -d stockCrawler.jar META-INF/LICENSE
 jar tvf stockCrawler.jar | grep -i license
 
 ## HDFS manipulation
 
 hadoop fs -ls
 hadoop fs -mkdir /user/${adminName}   
 hadoop fs -touch test
 hdfs dfs -copyFromLocal ${fileName}
 hdfs dfs -cat ${fileName}
 hadoop fs -rmr output
 hadoop jar stockCrawler.jar
 
 ## Some query example:
 db.quotes.find({&#39;historical_quotes.date&#39;:&#39;2015-04-10&#39;})
 
&lt;/code&gt;&lt;/pre&gt;
</description>
    </item>
    
  </channel>
</rss>